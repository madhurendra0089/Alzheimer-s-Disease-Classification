{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhurendra0089/Assignment/blob/main/2D_CNN_MRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rccXC6ue4vth"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the preprocessed data\n",
        "path = \"/content/drive/MyDrive/MRI_ED/\"\n",
        "\n",
        "# Load the preprocessed data\n",
        "x_train = np.load(path + 'x_train.npy')\n",
        "x_test = np.load(path + 'x_test.npy')\n",
        "x_val = np.load(path + 'x_val.npy')\n",
        "\n",
        "y_train = np.load(path + 'y_train.npy')\n",
        "y_test = np.load(path + 'y_test.npy')\n",
        "y_val = np.load(path + 'y_val.npy')\n",
        "\n",
        "print(f\"#x_train: {len(x_train)} #y_train: {len(y_train)} #x_val: {len(x_val)} #y_val: {len(y_val)} #x_test: {len(x_test)} #y_test: {len(y_test)}\")\n",
        "\n",
        "# Flatten 3D data into 2D slices\n",
        "def flatten_3d_to_2d(data):\n",
        "    temp = []\n",
        "    for i in range(len(data)):\n",
        "        for j in range(data.shape[-1]):  # Iterate over the third dimension (slices)\n",
        "            temp.append(data[i, :, :, j])\n",
        "    return np.array(temp)\n",
        "\n",
        "x_train = flatten_3d_to_2d(x_train)\n",
        "x_test = flatten_3d_to_2d(x_test)\n",
        "x_val = flatten_3d_to_2d(x_val)\n",
        "\n",
        "print(\"New shapes:\")\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"x_val shape: {x_val.shape}\")\n",
        "\n",
        "# Expand dimensions for CNN compatibility\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "x_val = np.expand_dims(x_val, axis=-1)\n",
        "\n",
        "print(\"After expanding dimensions:\")\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"x_val shape: {x_val.shape}\")\n",
        "\n",
        "# Adjust `y_train`, `y_test`, `y_val` to align with the flattened data\n",
        "y_train = np.repeat(y_train, x_train.shape[0] // len(y_train))\n",
        "y_test = np.repeat(y_test, x_test.shape[0] // len(y_test))\n",
        "y_val = np.repeat(y_val, x_val.shape[0] // len(y_val))\n",
        "\n",
        "print(\"Adjusted labels:\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")\n"
      ],
      "metadata": {
        "id": "4LwCy35MOT2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pGq9hRZ0-nZL"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "def CNN(width=100, height=100):\n",
        "    inputs = Input((width, height, 1))\n",
        "    x = Conv2D(4, 3, activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(8, 3, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(16, 3, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dense(16, activation='relu')(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = CNN(width=x_train.shape[1], height=x_train.shape[2])\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=16,\n",
        "    epochs=100,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "def performance(y_test, y_pred_binary):\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred_binary))\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_binary))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred_binary))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred_binary))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred_binary))\n",
        "\n",
        "performance(y_test, y_pred_binary)"
      ],
      "metadata": {
        "id": "Av-1k9-bN9TM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_XxbroJ2S6L3uhNzILoHhFSfADTSdg09",
      "authorship_tag": "ABX9TyPwdkre1uC6wpe7AKAV6VAl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}