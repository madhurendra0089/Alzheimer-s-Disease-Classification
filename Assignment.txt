
Question 1:

If we consider logistic regression without L1 or L2 regularization, the relationship between the old and new weights when duplicating a feature is straightforward. In logistic regression, the decision boundary is determined by the weights assigned to each feature. When you duplicate a feature, the weights associated with the duplicated features are expected to be similar.

Let w be the vector of weights learned from the initial logistic regression model with the original feature set. When you duplicate feature 
n into feature n+1 and retrain the model, the new weights Wnew for the extended feature set would likely have a relationship as follows:
Wnewi = Wi.    (For i=0,1,…,n)

In other words, the weights for the original features (i=0,1,…,n) remain unchanged when a feature is duplicated. The weights associated with the duplicated feature and the new feature (Wnewn+1) are expected to be similar to the weights of the original feature (wn).

This relationship assumes no regularization, and the impact of the duplicated feature is directly reflected in the weights assigned to both the original and duplicated features during the retraining process.







Question 2:

Let's denote the observed number of clicks for each template as O(B) ,O(C) ,O(D) ,O(E), and the total number of clicks as N (which is the same for all templates since you sent exactly 1000 emails for each template). The expected number of clicks under the assumption of no difference is E(i) =p(A), for each template.
Calculate Test Statistics:
X(i)^2 = (O(i) - E(i))^2/E(i), for i=B, C, D, E
The degrees of freedom (df) for each test is df=1 (since we are comparing each template to A).
Corrected Significance Level:
α(c) = α/(k-1), k is the number of templates being compared, so k=4
α=0.05
α(c) = 0.05/(4-1) = 0.0167
Chi-Squared Test:
For each test, compare the calculated test statistic to the critical value from the chi-squared distribution with 1 degree of freedom at the corrected significance level.
If X(i)^2>critical value, reject the null hypothesis for i=B,C,D,E.


Let's consider the corrected significance level for each comparison:

Corrected significance level:
α(c) = α/(k-1), k is the number of templates being compared, so k=4
α(c) = 0.05/(4-1) ≈ 0.0167

Now, we can compare the CTRs of each template to that of template A using the corrected significance level. If the p-value of a test is less than 0.0167, we reject the null hypothesis that the CTRs are the same.

Without the exact p-values, we cannot definitively choose the correct answer, but the correct answer would be the one consistent with the statistical comparison results.
We'll use a chi-squared test to compare each template to the control (A). Given that we have three templates to compare, we might use a significance level of 0.05/3 for each comparison to control the overall error rate.



option (a) is unlikely to be true, as we have data for all templates, and we can perform statistical tests to compare them.
option (b) is a possibility. We can compare the CTRs of templates B, C, D, and E to that of template A using statistical tests to determine which, if any, are significantly different.
option (c) is a strong claim. It suggests that both D and E are better than A, and both B and C are worse than A, all with 95% confidence.







Question 3:

In the context of logistic regression with sparse features, the computational cost per iteration of gradient descent can be significantly reduced due to the sparsity of the feature vectors. The exact computational cost can depend on the specific implementation details and the sparsity pattern.


Let's denote the number of training examples as 
m, the number of features as n, and the average number of non-zero entries in each training example as k, where k≪n.

The key factor that contributes to the computational cost in logistic regression is the evaluation of the gradient and the update of the weights. In the case of sparse features, the efficiency comes from the fact that we only need to consider non-zero entries in the feature vectors.

Here are some key considerations:

Gradient Evaluation:

For each training example, you only need to consider the non-zero entries, which reduces the cost significantly. The computational cost of evaluating the gradient for one training example can be approximately 

O(k) instead of O(n) in the case of dense features.  the approximate computational cost per iteration of logistic regression with sparse features can be on the order of 
O(k⋅m), where 

k is the average number of non-zero entries in each training example. This is significantly more efficient than O(n⋅m) for dense features when k≪n. The exact details may vary based on the specific implementation and 

optimization techniques used in the machine learning package.









Question 4:

1. Approach: Run V1 on 1 Million random stories, select 10k closest to the decision boundary:
This approach focuses on selecting examples that are challenging for the V1 classifier, as they are close to the decision boundary. This can be beneficial for improving the classifier's performance on ambiguous cases. These examples can help V2 better understand and handle cases where the decision is not clear-cut.

2. Approach: Get 10k random labeled stories:
This approach involves randomly selecting labeled stories. While this method provides diversity in the training data, it might not specifically target challenging cases. Randomly selected stories can cover a broad spectrum of topics and writing styles, contributing to a well-rounded training set. However, it may not focus on improving performance in the challenging cases.

3. Approach: Label 1 Million random stories, select 10k where V1 is both wrong and farthest from the decision boundary:
This approach targets cases where V1 is both wrong and has high uncertainty (far from the decision boundary). This can be valuable for improving the model's performance on cases where the current model is particularly weak. By focusing on instances where V1 is wrong and uncertain, the hope is to correct and better generalize from these challenging examples.

Overall Assessment:
Approach 1: Likely to improve accuracy by focusing on challenging cases near the decision boundary. This can help V2 handle ambiguous situations more effectively.

Approach 2: Contributes to the diversity of the training set but may not specifically address challenging cases. Still, it provides a broad spectrum of examples.

Approach 3: Targets challenging cases where the current model is wrong and uncertain. This approach aims to correct weaknesses in V1 and improve performance on difficult instances.

Potential Ranking:
Approach 3: This approach focuses on challenging cases where V1 is both wrong and uncertain, which can lead to significant improvements in the model's performance.

Approach 1: By selecting examples close to the decision boundary, this approach addresses ambiguous cases, improving the model's ability to handle uncertainty.

Approach 2: While providing diversity, randomly selecting labeled stories may not specifically target challenging cases. It contributes to a well-rounded training set but may not result in substantial improvements in handling difficult instances.

In summary, Approach 3 is likely to have the most impact on improving accuracy, followed by Approach 1, which addresses ambiguity near the decision boundary. Approach 2 contributes to overall diversity but may not focus on specific weaknesses in the current model.









Question 5:

The likelihood function for a binomial distribution is given by:

L(p;n,k)= nCk * p^k * (1−p) ^(n−k)

Taking the logarithm of the likelihood function (log-likelihood) and finding its derivative with respect to p, then setting it to zero gives the MLE:

Log L(p;n,k)= klogp+(n−k)log(1−p)

d/dp (Log L(p;n,k))= (k/p) - (n−k) / (1−p) = 0

Solving for p, we get:

^
pMLE = k / n


​2. Bayesian Estimate:
Given a uniform prior distribution over [0, 1], the posterior distribution is a Beta distribution with parameters 

α=k+1 and 

β=n−k+1. The expected value of a Beta distribution is given by:

E(Beta(α,β))= ​α / (α + β)
 

Substitute the parameters:


^
pBAYSEIAN = (k+1) / (n+2)


3. Maximum A Posteriori (MAP) Estimate:
The mode of a Beta distribution is given by:

mode(Beta(α,β))= (α−1) / (α+β−2)


Substitute the parameters:

^
pMAP = k / n





​
